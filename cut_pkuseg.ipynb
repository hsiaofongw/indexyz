{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkuseg\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "seg = pkuseg.pkuseg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_names = os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_contents = list()\n",
    "for article_name in article_names:\n",
    "    file_name = 'data/' + article_name\n",
    "    file = open(file_name, 'r')\n",
    "    article_content = file.read()\n",
    "    file.close()\n",
    "    article_contents.append(article_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles_from_folder(foldername: str) -> [str]:\n",
    "    article_names = os.listdir(foldername)\n",
    "    article_contents = list()\n",
    "    for article_name in article_names:\n",
    "        file_name = 'data/' + article_name\n",
    "        file = open(file_name, 'r')\n",
    "        article_content = file.read()\n",
    "        file.close()\n",
    "        article_contents.append(article_content)\n",
    "    \n",
    "    return article_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_articles_from_folder('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:18<00:00,  3.93it/s]\n"
     ]
    }
   ],
   "source": [
    "article_words = list()\n",
    "for i in tqdm(range(len(article_contents))):\n",
    "    article_content = article_contents[i]\n",
    "    words = seg.cut(article_content)\n",
    "    article_words.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter(l: list) -> dict:\n",
    "    stats = dict()\n",
    "    for i in range(len(l)):\n",
    "        item = l[i]\n",
    "        if item not in stats:\n",
    "            stats[item] = 1\n",
    "        else:\n",
    "            stats[item] = stats[item] + 1\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:00<00:00, 714.13it/s]\n"
     ]
    }
   ],
   "source": [
    "article_stats = list()\n",
    "for i in tqdm(range(len(article_words))):\n",
    "    article_stats.append(counter(article_words[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:00<00:00, 2145.72it/s]\n"
     ]
    }
   ],
   "source": [
    "all_term_stats = dict()\n",
    "for i in tqdm(range(len(article_stats))):\n",
    "    article_stat = article_stats[i]\n",
    "    for word, count in article_stat.items():\n",
    "        if word not in all_term_stats:\n",
    "            all_term_stats[word] = count\n",
    "        else:\n",
    "            all_term_stats[word] = all_term_stats[word] + count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_term_vector = list(all_term_stats.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:00<00:00, 180.62it/s]\n"
     ]
    }
   ],
   "source": [
    "doc_matrix = list()\n",
    "for i in tqdm(range(len(article_stats))):\n",
    "    stat_of_this_article = article_stats[i]\n",
    "    doc_matrix_row = list()\n",
    "    for term in all_term_vector:\n",
    "        if term in stat_of_this_article:\n",
    "            count = stat_of_this_article[term]\n",
    "        else:\n",
    "            count = 0\n",
    "        doc_matrix_row.append(count)\n",
    "    \n",
    "    doc_matrix.append(doc_matrix_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_indexes = pd.DataFrame({\n",
    "    'article_name': article_names,\n",
    "    'row_num_in_doc_matrix': range(len(article_names))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_indexes = pd.DataFrame({\n",
    "    'term': all_term_vector,\n",
    "    'col_num_in_doc_matrix': range(len(all_term_vector))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_indexes.to_csv('termdocmatrix/article_indexes.csv', index=False)\n",
    "\n",
    "term_indexes.to_csv('termdocmatrix/term_indexes.csv', index=False)\n",
    "\n",
    "np.savetxt(\n",
    "    fname = 'termdocmatrix/doc_matrix.txt',\n",
    "    X = np.array(doc_matrix).astype(int),\n",
    "    delimiter = ',',\n",
    "    newline = '\\n',\n",
    "    fmt = '%u'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_all_to_output(\n",
    "    article_indexes_filename: str,\n",
    "    term_indexes_filename: str,\n",
    "    doc_matrix_filename: str\n",
    "):\n",
    "\n",
    "    article_indexes.to_csv('termdocmatrix/article_indexes.csv', index=False)\n",
    "\n",
    "    term_indexes.to_csv('termdocmatrix/term_indexes.csv', index=False)\n",
    "\n",
    "    np.savetxt(\n",
    "        fname = 'termdocmatrix/doc_matrix.txt',\n",
    "        X = np.array(doc_matrix).astype(int),\n",
    "        delimiter = ',',\n",
    "        newline = '\\n',\n",
    "        fmt = '%u'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_all_to_output(\n",
    "\n",
    "    article_indexes: pd.DataFrame,\n",
    "    article_indexes_filename: str,\n",
    "\n",
    "    term_indexes: pd.DataFrame,\n",
    "    term_indexes_filename: str,\n",
    "\n",
    "    doc_matrix: [[int]],\n",
    "    doc_matrix_filename: str\n",
    "\n",
    ") -> None:\n",
    "\n",
    "    article_indexes.to_csv('termdocmatrix/article_indexes.csv', index=False)\n",
    "\n",
    "    term_indexes.to_csv('termdocmatrix/term_indexes.csv', index=False)\n",
    "\n",
    "    np.savetxt(\n",
    "        fname = 'termdocmatrix/doc_matrix.txt',\n",
    "        X = np.array(doc_matrix).astype(int),\n",
    "        delimiter = ',',\n",
    "        newline = '\\n',\n",
    "        fmt = '%u'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo() -> [int]:\n",
    "    return [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mike/jieba'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mike/jieba/data/a.txt'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(os.path.abspath('data/'), 'a.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-70-8b86236ed701>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-70-8b86236ed701>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    full_path = os.path.join(, article_name)\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def get_articles_from_folder(foldername: str) -> ([str], [str]):\n",
    "\n",
    "    abs_dir_path = os.path.abspath(foldername)\n",
    "    article_names = os.listdir(abs_dir_path)\n",
    "    article_contents = list()\n",
    "    for article_name in article_names:\n",
    "        full_path = os.path.join(, article_name)\n",
    "        file_name = full_path\n",
    "        file = open(file_name, 'r')\n",
    "        article_content = file.read()\n",
    "        file.close()\n",
    "        article_contents.append(article_content)\n",
    "    \n",
    "    return (article_names, article_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tuple.1 is article_names, tuple.2 is article_contents\n",
    "def get_articles_from_folder(foldername: str) -> ([str], [str]):\n",
    "\n",
    "    abs_dir_path = os.path.abspath(foldername)\n",
    "    article_names = os.listdir(abs_dir_path)\n",
    "    article_contents = list()\n",
    "    for article_name in article_names:\n",
    "        full_path = os.path.join(abs_dir_path, article_name)\n",
    "        file_name = full_path\n",
    "        file = open(file_name, 'r')\n",
    "        article_content = file.read()\n",
    "        file.close()\n",
    "        article_contents.append(article_content)\n",
    "    \n",
    "    return (article_names, article_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, contents = get_articles_from_folder('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1,2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import AnyStr, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cut_articles(\n",
    "    article_contents: [str], \n",
    "    cutter: Callable[[str], AnyStr]\n",
    ") -> [[str]]:\n",
    "    article_words = list()\n",
    "    for i in tqdm(range(len(article_contents))):\n",
    "        article_content = article_contents[i]\n",
    "        words = seg.cut(article_content)\n",
    "        article_words.append(words)\n",
    "    \n",
    "    return article_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutter = pkuseg.pkuseg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_arts = [\n",
    "    '你好天安门',\n",
    "    '我爱北京天安门',\n",
    "    '美丽的蓝天'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['你好天安门', '我爱北京天安门', '美丽的蓝天']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_arts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 2013.27it/s]\n"
     ]
    }
   ],
   "source": [
    "words = cut_articles(\n",
    "    my_arts,\n",
    "    cutter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['你好', '天安门'], ['我', '爱', '北京', '天安门'], ['美丽', '的', '蓝天']]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 统计一个列表中各个元素出现的次数\n",
    "def counter(l: list) -> dict:\n",
    "    stats = dict()\n",
    "    for i in range(len(l)):\n",
    "        item = l[i]\n",
    "        if item not in stats:\n",
    "            stats[item] = 1\n",
    "        else:\n",
    "            stats[item] = stats[item] + 1\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# 统计每篇文章的词频\n",
    "def do_stats(article_words: [[str]]) -> [Dict[str, int]]:\n",
    "    article_stats = list()\n",
    "    for i in tqdm(range(len(article_words))):\n",
    "        article_stats.append(counter(article_words[i]))\n",
    "    \n",
    "    return article_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 13329.36it/s]\n"
     ]
    }
   ],
   "source": [
    "s = do_stats(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 统计每一个出现过的单词的出现频数\n",
    "def make_all_term_stats(article_stats: [dict]) -> Dict[str, int]:\n",
    "    all_term_stats = dict()\n",
    "    for i in tqdm(range(len(article_stats))):\n",
    "        article_stat = article_stats[i]\n",
    "        for word, count in article_stat.items():\n",
    "            if word not in all_term_stats:\n",
    "                all_term_stats[word] = count\n",
    "            else:\n",
    "                all_term_stats[word] = all_term_stats[word] + count\n",
    "    \n",
    "    return all_term_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 15968.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'你好': 1, '天安门': 2, '我': 1, '爱': 1, '北京': 1, '美丽': 1, '的': 1, '蓝天': 1}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_all_term_stats(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
